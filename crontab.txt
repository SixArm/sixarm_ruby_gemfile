# Run the sync script for the DeallBreakers malls' ads,
# and delete any old files that we think are outdated.
#
# This runs nightly, just after the Adspace Top Ten server
# does its image linking (so the sync can download images)
# and does the database copy to the Clip'd server, which we
# use for downloading the ad.json files.
#  
# Eventually this sync is retired, when all of the app
# moves to the cloud and becomes real-time accessible.
#
30 6 * * * /usr/bin/find ~/sync/dealbreakers/malls/ -type f -mtime +60 -exec rm {} \; >> ~/sync_dealbreakers_malls.log
32 6 * * * ~/sync_dealbreakers_malls.sh >> ~/sync_dealbreakers_malls.log

# Fast-period syncs of each initiative's JSON file and images.
0,10,20,30,40,50 * * * * cd ~/sync/dealbreakers/malls/zzz && ~/bin/wget-dealbreakers-preview-all-in-one
2,12,22,32,42,52 * * * * cd ~/sync/GLOBAL/whatsonsale/data && ~/bin/wget-whatsonsale-player-schedule-all-in-one

# Run the monitor alerts, which should happen after the syncs above.
5,15,25,35,45,55 * * * * ~/bin/wget-whatsonsale-player-schedule-monitor



# Run the Twitter cacher for any accounts that we want.
# For now, we're just fetching the "Now This News" content
# that is tweeted by the Adspace account managed by Paul.
# This fetches via the Clip'd Rails app; if this works well
# then we want to move the Twitter cacher to the CDN server.
0 * * * * wget http://api.clipdapp.com/api/broadsign/twitter/cacher/tweets?screen_name=nowthisadspace -O ~/sync/GLOBAL/nowthis/headlines/data/headline.xml

# Output the current time stamp to a place where the players
# will be able to download it; this is essentially a canary.
0 * * * * ~/cycle_canary_xml.sh > ~/sync/GLOBAL/diagnostic/cycle.xml

# Create monitorsync sync zip file, then post the link to Slack.
# Business rule: sync happens at 11 a.m. Eastern on each weekday.
# Retain the sync zip file for 3 days.
0 15 * * Mon-Fri /usr/local/bin/adspace-cdn-sync-zip
@daily sudo nice find /home/monitorsync/sync_zip -ctime +3 -exec rm -f "{}" \;

